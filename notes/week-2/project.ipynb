{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Review Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ✅ Were you able to answer the data question asked i.e. What is our user repeat rate?\n",
    "- ✅ Were you able to create a marts folder for the three business lines?\n",
    "- ✅ Were you able to create at least 1 intermediate model and 1 dimension/fact model within each marts model?\n",
    "- ✅ Were you able to apply dbt tests to your week 1 or week 2 models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Repeate Customers\n",
    "1. What is our user repeat rate? Repeat Rate is defined as users who purchased 2 or more times / users who purchased\n",
    "2. What are good indicators of a user who will likely purchase again? \n",
    "3. What about indicators of users who are likely NOT to purchase again? \n",
    "4. If you had more data, what features would you want to look into to answer this question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://corise:corise@localhost:5432/dbt\n",
    "%config SqlMagic.displaylimit=100\n",
    "%config SqlMagic.displaycon = False\n",
    "%config SqlMagic.feedback = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>pct_users_repeat_purchase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0.80</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(Decimal('0.80'),)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "WITH nb_orders_by_user AS (\n",
    "SELECT user_id,\n",
    "       COUNT(DISTINCT order_id) AS nb_orders\n",
    "  FROM dbt_ramnath_v.stg_greenery__orders\n",
    " GROUP BY 1\n",
    ")\n",
    "\n",
    "SELECT ROUND(SUM(CASE WHEN nb_orders > 1 THEN 1 ELSE 0 END)::NUMERIC / COUNT(*), 2) AS pct_users_repeat_purchase\n",
    "  FROM nb_orders_by_user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would build a model that used features like recency of purchase, frequency of purchase, and the monetary value of the purchase to predict the probability that a customer would purchase again. I would also develop a model to predict customer LTV and apply it on a broader customer dataset to identify valuable customers to target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Create Mart Models\n",
    "\n",
    "Create a marts folder to organize models for business units (core, marketing, and product), and within each marts folder, create at least 1-2 intermediate models and 1-2 dimension/fact models.\n",
    "\n",
    "1. Explain the marts models you added. \n",
    "2. Why did you organize the models in the way you did?\n",
    "3. Use the dbt docs to visualize your model DAGs to ensure the model layers make sense\n",
    "4. Paste in an image of your DAG from the docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a folder for `core` models, and broke it down into three groups.\n",
    "\n",
    "1. `dimensions` folder to hold  `dim_***` models.\n",
    "2. `facts` folder to hold `fct_***` models.\n",
    "3. `intermediate` folder to hold intermediate models (`agg_***`, `int_***`).\n",
    "\n",
    "The idea is that these core models should constitute the single source of truth from which the marts and metrics should be built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/workspace/dbt-explore/dbt-greenery/models/marts/core\u001b[00m\n",
      "├── \u001b[01;34mdimensions\u001b[00m\n",
      "│   ├── dim_address.sql\n",
      "│   ├── dim_event.sql\n",
      "│   ├── dim_order.sql\n",
      "│   ├── dim_product.sql\n",
      "│   ├── dim_promo.sql\n",
      "│   ├── dim_tracking.sql\n",
      "│   ├── dim_user.sql\n",
      "│   └── README.md\n",
      "├── \u001b[01;34mfacts\u001b[00m\n",
      "│   ├── fct_place_order_product.sql\n",
      "│   ├── fct_place_order.sql\n",
      "│   ├── fct_register_event.sql\n",
      "│   └── fct_user.sql\n",
      "└── \u001b[01;34mintermediate\u001b[00m\n",
      "    ├── agg_events_by_user.sql\n",
      "    ├── agg_order_items_by_order.sql\n",
      "    └── agg_orders_by_user.sql\n",
      "\n",
      "3 directories, 15 files\n"
     ]
    }
   ],
   "source": [
    "!tree /workspace/dbt-explore/dbt-greenery/models/marts/core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dbt-greenery-core-dim-fact.png](dbt-greenery-core-dim-fact.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started creating `mart_***` and `metric_***` tables from the dimensional models. The idea is for a `mart_***` table to be a really wide table that combines multiple `dim_***` and `fct_***` tables that can eventually be turned into metrics automatically. I ran into some issues with the time-range of the different fact tables, which limited my ability to combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/workspace/dbt-explore/dbt-greenery/models/marts\u001b[00m\n",
      "├── \u001b[01;34mcore\u001b[00m\n",
      "│   ├── \u001b[01;34mdimensions\u001b[00m [8 entries exceeds filelimit, not opening dir]\n",
      "│   ├── \u001b[01;34mfacts\u001b[00m [4 entries exceeds filelimit, not opening dir]\n",
      "│   └── \u001b[01;34mintermediate\u001b[00m\n",
      "│       ├── agg_events_by_user.sql\n",
      "│       ├── agg_order_items_by_order.sql\n",
      "│       └── agg_orders_by_user.sql\n",
      "├── \u001b[01;34mmarketing\u001b[00m\n",
      "└── \u001b[01;34mproduct\u001b[00m\n",
      "    ├── mart_event.sql\n",
      "    └── metric_event.sql\n",
      "\n",
      "6 directories, 5 files\n"
     ]
    }
   ],
   "source": [
    "!tree /workspace/dbt-explore/dbt-greenery/models/marts --filelimit=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dbt-greenery-dag-week-2.png](dbt-greenery-dag-week-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What was most challenging/surprising in completing this week’s project?__\n",
    "\n",
    "The most challenging aspect of this week's project was to think through the architecture of the models and the naming conventions. I think I was able to arrive a solid set of conventions that I can already apply at work. The biggest learning for me was that breaking the `mart` layer into  three sub-layers: `dim` + `fact`, `mart`, and `metric` makes it really easy to compute arbitrary metrics of interest, while also making it BI tool friendly by providing ready-to-use wide datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Is there a particular part of the project where you want focused feedback from your reviewers?__\n",
    "\n",
    "I have tried to keep my facts \"pure\" at the grain level, leaving most aggregations to a metrics layer. I would love to get feedback on this approach, especially around its pros and cons and scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What are you most proud of about your project?__\n",
    "\n",
    "One of the useful utility tables I use at work is `date_periods` which is a `date_spine` on steroids and makes it easy to compute aggregates over multiple time periods in one shot. I was happy to recreate it as a macro using the `date_spine` macro to generate calendar dates and then adding custom logic to derive `date_periods`."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "625c31d6b4db3d7e7e2853cc30dc2062e1cda684f3e49d5f899ae496ae755fe0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
