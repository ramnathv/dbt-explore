{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Airflow needs a home. `~/airflow` is the default, but you can put it\n",
    "# somewhere else if you prefer (optional)\n",
    "export AIRFLOW_HOME=~/airflow\n",
    "\n",
    "# Install Airflow using the constraints file\n",
    "AIRFLOW_VERSION=2.2.2\n",
    "PYTHON_VERSION=\"$(python --version | cut -d \" \" -f 2 | cut -d \".\" -f 1-2)\"\n",
    "# For example: 3.6\n",
    "CONSTRAINT_URL=\"https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt\"\n",
    "# For example: https://raw.githubusercontent.com/apache/airflow/constraints-2.2.2/constraints-3.6.txt\n",
    "# echo \"apache-airflow==${AIRFLOW_VERSION}\" --constraint \"${CONSTRAINT_URL}\"\n",
    "pip install --upgrade pip\n",
    "pip install \"apache-airflow==${AIRFLOW_VERSION}\" --constraint \"${CONSTRAINT_URL}\" --user\n",
    "\n",
    "# # The Standalone command will initialise the database, make a user,\n",
    "# # and start all components for you.\n",
    "# airflow standalone\n",
    "\n",
    "# Visit localhost:8080 in the browser and use the admin account details\n",
    "# shown on the terminal to login.\n",
    "# Enable the example_bash_operator dag in the home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE ROLE\n",
      "CREATE SCHEMA\n",
      "Running with dbt=0.21.0\n",
      "WARNING: Found patch for macro \"is_positive\" which was not found\n",
      "Found 29 models, 32 tests, 4 snapshots, 0 analyses, 560 macros, 1 operation, 0 seed files, 8 sources, 1 exposure\n",
      "\n",
      "17:26:23 | Concurrency: 4 threads (target='dev')\n",
      "17:26:23 | \n",
      "17:26:24 | Done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "env PGPASSWORD=corise psql -U corise -d dbt -c 'CREATE ROLE reporting;'\n",
    "env PGPASSWORD=corise psql -U corise -d dbt -c 'CREATE SCHEMA dbt_ramnath_v'\n",
    "dbt compile --project-dir=/workspace/dbt-explore/dbt-greenery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /home/gitpod/airflow/dags/dbt-greenery.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/airflow/dags/dbt-greenery.py\n",
    "import logging\n",
    "from copy import copy\n",
    "from logging import Logger\n",
    "from typing import Dict, List, Optional\n",
    "from airflow_dbt.operators.dbt_operator import (\n",
    "    DbtSeedOperator,\n",
    "    DbtSnapshotOperator,\n",
    "    DbtRunOperator,\n",
    "    DbtTestOperator,\n",
    ")\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.models import Variable, BaseOperator\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.utils.task_group import TaskGroup\n",
    "\n",
    "DbtRunOperator.ui_color = '#f5f5dc'\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class DbtNode:\n",
    "    def __init__(self, full_name: str, children: List[str], config: Optional[dict]):\n",
    "        self.full_name = full_name\n",
    "        self.children = children\n",
    "        self.is_model = self.full_name.startswith('model')\n",
    "        self.name = self.full_name.split('.')[-1]\n",
    "        self.is_persisted = self.is_model and config[\"materialized\"] in ['table', 'incremental', 'view']\n",
    "\n",
    "\n",
    "class DbtTaskGenerator:\n",
    "\n",
    "    def __init__(\n",
    "        self, dag: DAG, manifest: dict\n",
    "    ) -> None:\n",
    "        self.dag: DAG = dag\n",
    "        self.manifest = manifest\n",
    "        self.persisted_node_map: Dict[str, DbtNode] = self._get_persisted_parent_to_child_map()\n",
    "        self.logger: Logger = logging.getLogger(__name__)\n",
    "\n",
    "    def _get_persisted_parent_to_child_map(self) -> Dict[str, DbtNode]:\n",
    "        node_info = self.manifest['nodes']\n",
    "        parent_to_child_map = self.manifest['child_map']\n",
    "\n",
    "        all_nodes: Dict[str, DbtNode] = {\n",
    "            node_name: DbtNode(\n",
    "                full_name=node_name,\n",
    "                children=children,\n",
    "                config=node_info.get(node_name, {}).get('config')\n",
    "            )\n",
    "            for node_name, children in parent_to_child_map.items()\n",
    "        }\n",
    "\n",
    "        persisted_nodes = {\n",
    "            node.full_name: DbtNode(\n",
    "                full_name=node.full_name,\n",
    "                children=self._get_persisted_children(node, all_nodes),\n",
    "                config=node_info.get(node_name, {}).get('config')\n",
    "            )\n",
    "            for node_name, node in all_nodes.items()\n",
    "            if node.is_persisted and node.full_name\n",
    "        }\n",
    "\n",
    "        return persisted_nodes\n",
    "\n",
    "    @classmethod\n",
    "    def _get_persisted_children(cls, node: DbtNode, all_nodes: Dict[str, DbtNode]) -> List[str]:\n",
    "        persisted_children = []\n",
    "        for child_key in node.children:\n",
    "            child_node = all_nodes[child_key]\n",
    "            if child_node.is_persisted:\n",
    "                persisted_children.append(child_key)\n",
    "            else:\n",
    "                persisted_children += cls._get_persisted_children(child_node, all_nodes)\n",
    "\n",
    "        return persisted_children\n",
    "\n",
    "    def add_all_tasks(self) -> None:\n",
    "        nodes_to_add: Dict[str, DbtNode] = {}\n",
    "        for node in self.persisted_node_map:\n",
    "            included_node = copy(self.persisted_node_map[node])\n",
    "            included_children = []\n",
    "            for child in self.persisted_node_map[node].children:\n",
    "                included_children.append(child)\n",
    "            included_node.children = included_children\n",
    "            nodes_to_add[node] = included_node\n",
    "\n",
    "        self._add_tasks(nodes_to_add)\n",
    "\n",
    "    def _add_tasks(self, nodes_to_add: Dict[str, DbtNode]) -> None:\n",
    "        dbt_model_tasks = self._create_dbt_run_model_tasks(nodes_to_add)\n",
    "        self.logger.info(f'{len(dbt_model_tasks)} tasks created for models')\n",
    "\n",
    "        for parent_node in nodes_to_add.values():\n",
    "            if parent_node.is_model:\n",
    "                self._add_model_dependencies(dbt_model_tasks, parent_node)\n",
    "\n",
    "    def _create_dbt_run_model_tasks(self, nodes_to_add: Dict[str, DbtNode]) -> Dict[str, BaseOperator]:\n",
    "        # dbt_docker_image_details = Variable.get(\"docker_dbt-data-platform\", deserialize_json=True)\n",
    "        dbt_model_tasks: Dict[str, BaseOperator] = {\n",
    "            node.full_name: self._create_dbt_run_task(node.name)\n",
    "            for node in nodes_to_add.values()\n",
    "            if node.is_model\n",
    "        }\n",
    "        return dbt_model_tasks\n",
    "\n",
    "    def _create_dbt_run_task(self, model_name: str) -> BaseOperator:\n",
    "        # This is where you create a task to run the model - see\n",
    "        # https://docs.getdbt.com/docs/running-a-dbt-project/running-dbt-in-production#using-airflow\n",
    "        # We pass the run date into our models: f'dbt run --models={model_name} --vars '{\"run_date\":\"\"}'\n",
    "        # return DummyOperator(dag=self.dag, task_id=model_name)\n",
    "        return DbtRunOperator(\n",
    "            dag=self.dag, \n",
    "            task_id=model_name, \n",
    "            dir='/workspace/dbt-explore/dbt-greenery',\n",
    "            models=model_name,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_model_dependencies(dbt_model_tasks: Dict[str, BaseOperator], parent_node: DbtNode) -> None:\n",
    "        for child_key in parent_node.children:\n",
    "            child = dbt_model_tasks.get(child_key)\n",
    "            if child:\n",
    "                dbt_model_tasks[parent_node.full_name] >> child\n",
    "\n",
    "from datetime import datetime\n",
    "from airflow import DAG\n",
    "import json\n",
    "import os\n",
    "\n",
    "CUR_DIR = os.path.abspath(os.path.dirname(__file__))\n",
    "with open(f\"{CUR_DIR}/manifest.json\", \"r\") as file:\n",
    "    manifest = json.load(file)\n",
    "\n",
    "dag = DAG(\n",
    "    dag_id=\"dbt_connected_task_creator_test_dag\",\n",
    "    start_date=datetime(2021, 12, 6),\n",
    "    schedule_interval=\"0 1 * * *\",\n",
    ")\n",
    "dbt_task_generator = DbtTaskGenerator(dag, manifest)\n",
    "dbt_task_generator.add_all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp dags/foobar.py ~/airflow/dags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import json\n",
    "\n",
    "class DbtNode:\n",
    "    def __init__(self, node_name: str, node_info: Dict, node_children: List):\n",
    "        self.node_info = node_info\n",
    "        self.node_name = node_name\n",
    "        self.parents = node_info.get('depends_on', {}).get('nodes', [])\n",
    "        self.children = node_children\n",
    "        self.materialized = node_info.get('config', {}).get('materialized', '')\n",
    "        self.is_model = node_name.startswith('model')\n",
    "        self.is_persisted = self.is_model and self.materialized in ['table', 'incremental', 'view']\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<DbtNode> {self.node_name} ({self.materialized})'\n",
    "\n",
    "@dataclass\n",
    "class DbtProject:\n",
    "    dbt_project_dir: str = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.manifest = self.__load_manifest()\n",
    "        self.nodes = self.__load_nodes()\n",
    "\n",
    "    def __load_manifest(self):\n",
    "        manifest_path = Path(self.dbt_project_dir) / 'target/manifest.json'\n",
    "        return json.loads(manifest_path.read_text())\n",
    "\n",
    "    def __load_nodes(self):\n",
    "        child_map = self.manifest['child_map']\n",
    "        return [\n",
    "            DbtNode(\n",
    "              node_name, \n",
    "              node_info, \n",
    "              child_map.get(node_name, [])\n",
    "            ) \n",
    "            for node_name, node_info in self.manifest.get('nodes', {}).items()\n",
    "        ]\n",
    "            \n",
    "\n",
    "\n",
    "dbt = DbtProject('/workspace/dbt-explore/dbt-greenery')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "625c31d6b4db3d7e7e2853cc30dc2062e1cda684f3e49d5f899ae496ae755fe0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
